{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e11f59-495b-4489-b8bc-3596aa492575",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------- Mathematics for AI -----------------------------------------#\n",
    "\n",
    "Here’s exactly what that chapter should cover (in the right order), with what each topic is for.\n",
    "________________________________________\n",
    "1) Foundations (the “language”)\n",
    "Sets, functions, notation\n",
    "#Why: ML papers + formulas use this constantly.\n",
    "You need: function mapping, domains, ranges, basic symbols.\n",
    "Logarithms & exponentials\n",
    "#Why: loss functions, softmax, probability, p-values.\n",
    "________________________________________\n",
    "2) Linear Algebra (the skeleton of ML)\n",
    "Vectors & matrices\n",
    "#Why: all data becomes a matrix X, all models are matrix operations.\n",
    "Dot product, matrix multiplication\n",
    "#Why: prediction in linear models = Xw\n",
    "Norms & distance (L1, L2)\n",
    "#Why: regularization, kNN, similarity.\n",
    "Eigenvalues/eigenvectors (idea level)\n",
    "#Why: PCA, stability, transformations.\n",
    "SVD (Singular Value Decomposition)\n",
    "#Why: PCA in practice, compression, embeddings.\n",
    "________________________________________\n",
    "3) Calculus (how models learn)\n",
    "Derivatives (single variable)\n",
    "#Why: slope = “how changing x changes output”.\n",
    "Partial derivatives (multi-variable)\n",
    "#Why: models have many parameters.\n",
    "Gradients\n",
    "#Why: direction to update weights.\n",
    "Chain rule\n",
    "#Why: backpropagation (core of deep learning).\n",
    "________________________________________\n",
    "4) Optimization (training = minimizing)\n",
    "Gradient descent variants\n",
    "•\tbatch, mini-batch, SGD\n",
    "#Why: how training actually updates weights.\n",
    "Learning rate + convergence intuition\n",
    "#Why: most training problems are learning-rate problems.\n",
    "Convex vs non-convex (intuition)\n",
    "#Why: deep nets are non-convex; we still train them.\n",
    "________________________________________\n",
    "5) Probability (uncertainty + prediction)\n",
    "Random variables, distributions\n",
    "#Why: data is noisy; models predict under uncertainty.\n",
    "Expectation, variance, covariance\n",
    "#Why: bias/variance, correlation, PCA, uncertainty.\n",
    "Bayes theorem (intuition)\n",
    "#Why: posterior reasoning, Naive Bayes, probabilistic thinking.\n",
    "________________________________________\n",
    "6) Statistics (making claims from data)\n",
    "Sampling, central limit theorem\n",
    "#Why: why averages behave; why “n” matters.\n",
    "Confidence intervals\n",
    "#Why: uncertainty around metrics.\n",
    "Hypothesis testing (p-values basics)\n",
    "#Why: comparing models/experiments.\n",
    "________________________________________\n",
    "7) Information Theory (optional but powerful)\n",
    "Entropy, cross-entropy, KL divergence\n",
    "#Why: classification loss, model comparison, generative models.\n",
    "________________________________________\n",
    "8) ML-specific math “glue”\n",
    "Logistic function + log loss\n",
    "#Why: classification foundation.\n",
    "Softmax\n",
    "#Why: multi-class classification.\n",
    "Regularization (L1/L2)\n",
    "#Why: prevent overfitting, feature selection.\n",
    "________________________________________\n",
    "The best learning path (simple order)\n",
    "1.\tLinear algebra\n",
    "2.\tProbability + stats basics\n",
    "3.\tCalculus + optimization\n",
    "4.\tInformation theory\n",
    "5.\tML glue (log loss, softmax, regularization)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8648863-9fa6-422f-9061-345dff570979",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.1 What is a function? (Very important)\n",
    "\n",
    "In AI, almost everything is a function.\n",
    "\n",
    "#A function is just: Input → Rule → Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0b62c1-c111-49d6-a76d-8a5038a701e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Example:\n",
    "\n",
    "--Input: age\n",
    "--Rule: multiply by 2\n",
    "--Output: new number\n",
    "\n",
    "In math notation:\n",
    "f(x) = 2x\n",
    "\n",
    "Why this matters for AI\n",
    "\n",
    "A model is a function.\n",
    "\n",
    "Example:\n",
    "y = f(x)\n",
    "\n",
    "Where:\n",
    "\n",
    "x = input features\n",
    "y = prediction\n",
    "f = model\n",
    "\n",
    "#Logistic regression, neural networks, transformers — all are just big functions.\n",
    "\n",
    "Let’s visualize this in Python (no heavy math yet)\n",
    "\n",
    "Run this:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2be5193-3157-4345-b3e0-cdf8425feef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 10, 20)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A simple function\n",
    "def f(x):\n",
    "    return 2 * x\n",
    "\n",
    "# Try inputs\n",
    "f(2), f(5), f(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a6d68c-ed81-4112-b80d-5f09ccb82376",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.2 Domain and Range\n",
    "\n",
    "-Domain = all possible inputs\n",
    "-Range = all possible outputs\n",
    "\n",
    "If:\n",
    "f(x) = x²\n",
    "\n",
    "Then:\n",
    "\n",
    "-Domain: all real numbers\n",
    "-Range: only ≥ 0\n",
    "\n",
    "This matters in AI because:\n",
    "\n",
    "--Some functions only accept certain inputs (like log, sqrt)\n",
    "--Some activations have limited output ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def1578d-4f6e-4e9b-a229-3f24cc21ac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.3 Linear vs Non-linear (super important)\n",
    "Linear function:\n",
    "\n",
    "f(x) = 2x\n",
    "Graph = straight line\n",
    "\n",
    "Non-linear function:\n",
    "\n",
    "f(x) = x²\n",
    "f(x) = sin(x)\n",
    "f(x) = log(x)\n",
    "Graph = curves\n",
    "\n",
    "Why this matters\n",
    "\n",
    "--If models were only linear, they’d be weak.\n",
    "--Neural networks = stacking non-linear functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62735c4b-f745-4971-8791-c289101d5156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(-10, 10, 100)\n",
    "\n",
    "y1 = 2*x        # linear\n",
    "y2 = x**2       # non-linear\n",
    "\n",
    "plt.plot(x, y1, label=\"2x\")\n",
    "plt.plot(x, y2, label=\"x^2\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef77e8be-17d0-41f3-bf09-608dcd03b2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    " Module 1 — Data Math Foundations for AI (Real-world, beginner)\n",
    "\n",
    "What you will build (project)\n",
    "\n",
    "Project: “Delivery Time Helper”\n",
    "\n",
    "Given a new order (distance, traffic, weather…), we will:\n",
    "\n",
    "1.\tclean the dataset (missing values + outliers)\n",
    "2.\tcompute core stats (mean/median/std/percentiles)\n",
    "3.\tscale features (so one feature doesn’t bully the others)\n",
    "4.\tfind most similar past deliveries using cosine similarity\n",
    "5.\tpredict delivery time using simple “similar-past-average” (a baby ML baseline)\n",
    "\n",
    "This is real-world and used in:\n",
    "\n",
    "•\tETA prediction (Swiggy/Zomato/Amazon)\n",
    "•\trecommender systems (similarity)\n",
    "•\tembeddings search (cosine similarity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f4523e-6077-4bc2-ab75-df3863eb228d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Step 0 — Setup (imports)\n",
    "\n",
    "Why\n",
    "\n",
    "We need tools:\n",
    "•\tnumpy = fast math\n",
    "•\tpandas = tables like Excel but smarter\n",
    "•\tmatplotlib = quick graphs to see issues\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bacd8b33-3274-4239-a792-219442b50bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd0d8fc-750f-4624-860c-acfcf5d39922",
   "metadata": {},
   "outputs": [],
   "source": [
    "Step 1 — Create a realistic dataset (with problems on purpose)\n",
    "\n",
    "Why\n",
    "\n",
    "Real data is not clean. It has:\n",
    "•\tmissing values\n",
    "•\toutliers\n",
    "•\tnoise\n",
    "\n",
    "We’ll generate something like an operations dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d66c55c7-7588-4c0b-8b61-af4cd38f01dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_km</th>\n",
       "      <th>traffic</th>\n",
       "      <th>weather_rain</th>\n",
       "      <th>prep_time_min</th>\n",
       "      <th>items</th>\n",
       "      <th>delivery_time_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.831399</td>\n",
       "      <td>1.907202</td>\n",
       "      <td>0</td>\n",
       "      <td>16.014220</td>\n",
       "      <td>7</td>\n",
       "      <td>53.840695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.718051</td>\n",
       "      <td>1.204569</td>\n",
       "      <td>0</td>\n",
       "      <td>14.232624</td>\n",
       "      <td>1</td>\n",
       "      <td>88.666392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.521822</td>\n",
       "      <td>0.508463</td>\n",
       "      <td>0</td>\n",
       "      <td>10.821232</td>\n",
       "      <td>1</td>\n",
       "      <td>56.501091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.363164</td>\n",
       "      <td>1.998812</td>\n",
       "      <td>0</td>\n",
       "      <td>17.615998</td>\n",
       "      <td>6</td>\n",
       "      <td>92.750446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.471748</td>\n",
       "      <td>0.571660</td>\n",
       "      <td>1</td>\n",
       "      <td>12.754601</td>\n",
       "      <td>5</td>\n",
       "      <td>85.901460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   distance_km   traffic  weather_rain  prep_time_min  items  \\\n",
       "0     2.831399  1.907202             0      16.014220      7   \n",
       "1    19.718051  1.204569             0      14.232624      1   \n",
       "2    11.521822  0.508463             0      10.821232      1   \n",
       "3    18.363164  1.998812             0      17.615998      6   \n",
       "4    24.471748  0.571660             1      12.754601      5   \n",
       "\n",
       "   delivery_time_min  \n",
       "0          53.840695  \n",
       "1          88.666392  \n",
       "2          56.501091  \n",
       "3          92.750446  \n",
       "4          85.901460  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(7)  # WHY: makes results repeatable (same random data every run)\n",
    "\n",
    "n = 300\n",
    "\n",
    "# Features (inputs)\n",
    "distance_km = np.random.uniform(1, 25, n)                     # 1–25 km\n",
    "traffic = np.random.uniform(0.5, 2.0, n)                      # traffic multiplier\n",
    "weather = np.random.choice([0, 1], size=n, p=[0.8, 0.2])       # 0=clear, 1=rain\n",
    "prep_time = np.random.normal(12, 4, n).clip(3, 30)             # restaurant prep time\n",
    "items = np.random.randint(1, 8, n)                             # number of items\n",
    "\n",
    "# Target (output): delivery time (minutes)\n",
    "# WHY this formula: reality = distance + traffic + weather + prep + noise\n",
    "delivery_time = (\n",
    "    8\n",
    "    + distance_km * 2.4\n",
    "    + traffic * 10\n",
    "    + weather * 7\n",
    "    + prep_time * 0.9\n",
    "    + items * 1.2\n",
    "    + np.random.normal(0, 4, n)  # noise\n",
    ")\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"distance_km\": distance_km,\n",
    "    \"traffic\": traffic,\n",
    "    \"weather_rain\": weather,\n",
    "    \"prep_time_min\": prep_time,\n",
    "    \"items\": items,\n",
    "    \"delivery_time_min\": delivery_time\n",
    "})\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11659666-9f4b-44f5-93de-76a42e1fc787",
   "metadata": {},
   "source": [
    "Step 2 — Inject real-world issues: missing values + outliers\r\n",
    "\r\n",
    "Why\r\n",
    "\r\n",
    "Because your real tickets (work life) will always have “some rows broken”.\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c153cd2-648b-49e4-93c6-82f8cb25f053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distance_km           0\n",
       "traffic              12\n",
       "weather_rain          0\n",
       "prep_time_min        12\n",
       "items                 0\n",
       "delivery_time_min     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add missing values (NaN)\n",
    "for col in [\"traffic\", \"prep_time_min\"]:\n",
    "    idx = np.random.choice(df.index, size=12, replace=False)\n",
    "    df.loc[idx, col] = np.nan\n",
    "\n",
    "# Add outliers (crazy values)\n",
    "df.loc[np.random.choice(df.index, 3, replace=False), \"distance_km\"] = 120   # impossible distance\n",
    "df.loc[np.random.choice(df.index, 3, replace=False), \"delivery_time_min\"] = 300  # insane time\n",
    "\n",
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a231df90-07b0-4af2-a406-3a7502aea512",
   "metadata": {},
   "outputs": [],
   "source": [
    "What you learned:\n",
    "\n",
    "•\tNaN means missing value\n",
    "•\toutliers are extreme values that mess with mean/std/models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba41a79-37f8-4d51-895d-1bbdf852cf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Step 3 — Core statistics (the “language” of data)\n",
    "\n",
    "3.1 Mean vs Median (super important)\n",
    "\n",
    "Why\n",
    "•\tMean gets pulled by outliers\n",
    "•\tMedian is more “outlier-proof”\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51f7cfb9-b275-4c29-aeb8-da62f2f4da76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean  : 70.81189215251646\n",
      "Median: 69.17846737326805\n"
     ]
    }
   ],
   "source": [
    "col = \"delivery_time_min\"\n",
    "\n",
    "mean_val = df[col].mean()\n",
    "median_val = df[col].median()\n",
    "\n",
    "print(\"Mean  :\", mean_val)\n",
    "print(\"Median:\", median_val)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ee9474-378f-4a59-b0c7-003b45a9f73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "✅ If mean ≫ median, outliers probably exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bb38a8-0869-4a29-a984-b293daefe434",
   "metadata": {},
   "outputs": [],
   "source": [
    "✅ If mean ≫ median, outliers probably exist. 3.2 Variance + Standard Deviation (spread)\n",
    "\n",
    "Why\n",
    "\n",
    "ML needs to know how spread out data is.\n",
    "•\tvariance = average squared spread\n",
    "•\tstd = square root of variance (same unit as data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7721cb7e-b81d-40fe-9baa-2522af2e2a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Std : 29.621114516101624\n",
      "Var : 877.4104251760064\n"
     ]
    }
   ],
   "source": [
    "std_val = df[col].std()\n",
    "var_val = df[col].var()\n",
    "\n",
    "print(\"Std :\", std_val)\n",
    "print(\"Var :\", var_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b4bb9b-c29d-439a-905f-cb576754e4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "3.3 Percentiles (better than mean sometimes)\n",
    "\n",
    "Why\n",
    "\n",
    "Percentiles tell you boundaries.\n",
    "•\t50th percentile = median\n",
    "•\t90th percentile = “most are below this”\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "129040f9-083f-4f39-a3b5-3a6f180ea6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50%: 69.17846737326805\n",
      "90%: 92.6781422552057\n",
      "99%: 112.05630654440884\n"
     ]
    }
   ],
   "source": [
    "p50 = df[col].quantile(0.50)\n",
    "p90 = df[col].quantile(0.90)\n",
    "p99 = df[col].quantile(0.99)\n",
    "\n",
    "print(\"50%:\", p50)\n",
    "print(\"90%:\", p90)\n",
    "print(\"99%:\", p99)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2a514a-491a-441a-b638-63fa3945a4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Step 4 — Visual check (fast truth detector)\n",
    "Why\n",
    "Graphs reveal issues your eyes miss in tables.\n",
    "df[\"delivery_time_min\"].hist(bins=30)\n",
    "plt.xlabel(\"Delivery Time (min)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "If you see a long tail or extreme bars → outliers.\n",
    "________________________________________\n",
    "Step 5 — Fix missing values (NaN)\n",
    "Strategy (real-world)\n",
    "•\tFor skew/outliers: use median\n",
    "•\tFor normal-ish: use mean\n",
    "•\tFor categories: use mode\n",
    "We’ll use median for traffic and prep_time_min (safe choice).\n",
    "df_fixed = df.copy()\n",
    "\n",
    "for col in [\"traffic\", \"prep_time_min\"]:\n",
    "    median_value = df_fixed[col].median()\n",
    "    df_fixed[col] = df_fixed[col].fillna(median_value)\n",
    "\n",
    "df_fixed.isna().sum()\n",
    "Why fillna(median) works:\n",
    "Median doesn’t get fooled by outliers, so it’s stable.\n",
    "________________________________________\n",
    "Step 6 — Fix outliers (IQR method)\n",
    "Why\n",
    "Outliers destroy:\n",
    "•\tmean/std\n",
    "•\tscaling\n",
    "•\tdistance/similarity calculations\n",
    "•\tmodel training\n",
    "IQR method (classic, practical):\n",
    "•\tIQR = Q3 − Q1\n",
    "•\tlower = Q1 − 1.5×IQR\n",
    "•\tupper = Q3 + 1.5×IQR\n",
    "Then we “cap” values (winsorize) instead of deleting rows.\n",
    "def cap_outliers_iqr(s):\n",
    "    q1 = s.quantile(0.25)\n",
    "    q3 = s.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    low = q1 - 1.5 * iqr\n",
    "    high = q3 + 1.5 * iqr\n",
    "    return s.clip(low, high)\n",
    "\n",
    "for col in [\"distance_km\", \"delivery_time_min\"]:\n",
    "    df_fixed[col] = cap_outliers_iqr(df_fixed[col])\n",
    "\n",
    "df_fixed[[\"distance_km\", \"delivery_time_min\"]].describe()\n",
    "Why capping is good:\n",
    "You keep data size, but remove crazy influence.\n",
    "________________________________________\n",
    "Step 7 — Scaling (most important ML prep)\n",
    "Why scaling exists\n",
    "If one feature has big numbers, it dominates learning.\n",
    "Example:\n",
    "•\tdistance = up to 25\n",
    "•\tprep_time = up to 30\n",
    "•\ttraffic = 0.5–2.0\n",
    "If we later use distances/dot products/gradients, unscaled features distort everything.\n",
    "7.1 Standardization (Z-score)\n",
    "Formula:\n",
    "z = (x − mean) / std\n",
    "Result: mean ≈ 0, std ≈ 1\n",
    "features = [\"distance_km\", \"traffic\", \"weather_rain\", \"prep_time_min\", \"items\"]\n",
    "X = df_fixed[features].values\n",
    "\n",
    "mu = X.mean(axis=0)\n",
    "sigma = X.std(axis=0)\n",
    "\n",
    "Xz = (X - mu) / sigma\n",
    "7.2 Min-Max normalization\n",
    "Formula:\n",
    "x_norm = (x − min) / (max − min)\n",
    "Result: all values in 0..1\n",
    "xmin = X.min(axis=0)\n",
    "xmax = X.max(axis=0)\n",
    "\n",
    "Xmm = (X - xmin) / (xmax - xmin)\n",
    "When to use what (real rule):\n",
    "•\tZ-score: most ML models, gradient descent, linear/logistic regression, neural nets\n",
    "•\tMin-max: when you want bounded values (0..1), some NN setups, some distance methods\n",
    "________________________________________\n",
    "Step 8 — Similarity (cosine) to find “similar past deliveries”\n",
    "Why cosine similarity\n",
    "This is used everywhere:\n",
    "•\tembeddings search (ChatGPT retrieval style)\n",
    "•\trecommendations\n",
    "•\tsimilarity-based predictions\n",
    "Cosine similarity measures angle between vectors (pattern similarity), not size.\n",
    "def cosine_similarity_matrix(A, b):\n",
    "    # A: (n, d), b: (d,)\n",
    "    b = b.reshape(1, -1)\n",
    "    num = A @ b.T                       # dot products (n,1)\n",
    "    den = np.linalg.norm(A, axis=1, keepdims=True) * np.linalg.norm(b)\n",
    "    return (num / den).ravel()          # (n,)\n",
    "________________________________________\n",
    "Step 9 — Make the baseline predictor (real project solution)\n",
    "We’ll predict delivery time for a new order by:\n",
    "1.\tstandardize it using training mean/std\n",
    "2.\tfind top-k similar deliveries using cosine\n",
    "3.\taverage their delivery time\n",
    "y = df_fixed[\"delivery_time_min\"].values\n",
    "\n",
    "# Use standardized features for similarity\n",
    "A = Xz  # (n,d)\n",
    "\n",
    "# New order scenario (you can change these values)\n",
    "new_order = np.array([8.0, 1.6, 1, 14.0, 3])  # distance, traffic, rain, prep, items\n",
    "\n",
    "# Standardize new order using same mu/sigma\n",
    "new_z = (new_order - mu) / sigma\n",
    "\n",
    "# Similarities\n",
    "sims = cosine_similarity_matrix(A, new_z)\n",
    "\n",
    "# Top k neighbors\n",
    "k = 10\n",
    "topk_idx = np.argsort(sims)[-k:][::-1]\n",
    "\n",
    "pred = y[topk_idx].mean()\n",
    "print(\"Predicted delivery time (min):\", pred)\n",
    "\n",
    "print(\"\\nTop-10 similar deliveries (index, similarity, time):\")\n",
    "for i in topk_idx[:5]:\n",
    "    print(i, round(sims[i], 3), round(y[i], 1))\n",
    "✅ This is a legit “starter AI system”: similarity-based estimation.\n",
    "________________________________________\n",
    "What notes you MUST write (only these)\n",
    "Write this on one page:\n",
    "1.\tmean vs median (median safer with outliers)\n",
    "2.\tstd = spread\n",
    "3.\tpercentiles (90%, 99%) for boundaries\n",
    "4.\tZ-score: (x − mean) / std\n",
    "5.\tMin-max: (x − min) / (max − min)\n",
    "6.\tCosine similarity: dot(a,b) / (||a||·||b||)\n",
    "That’s your “Module 1 brain”.\n",
    "________________________________________\n",
    "Mini tasks (we will solve as you go)\n",
    "Do these inside the same notebook:\n",
    "Task A\n",
    "Change new_order to:\n",
    "•\t[3, 0.7, 0, 8, 1] (easy order)\n",
    "•\t[20, 1.9, 1, 20, 6] (hard order)\n",
    "See predicted time difference.\n",
    "Task B\n",
    "Change k = 3 and k = 30\n",
    "See how prediction changes (bias-variance intuition starting).\n",
    "________________________________________\n",
    "Module 1 complete topics covered (maximum, practical)\n",
    "•\tmean/median/variance/std\n",
    "•\tpercentiles\n",
    "•\tmissing values handling\n",
    "•\toutlier detection + capping (IQR)\n",
    "•\tscaling (z-score, min-max)\n",
    "•\tdot product + cosine similarity\n",
    "•\treal project baseline predictor using similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ea00d84-401b-4d00-b6ab-0606572c38fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGwCAYAAABcnuQpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAr+klEQVR4nO3de3QUZZ7/8U8HQptAEu7pRCJECBwxgkgQg6simiACwuEcBwd148ELXlAZZtcdZJTGcQIyawZ3Mt5mh8vsEdmzR7zsyC0KBFyW2YAyBMZhvAAqJGbVSCKBTpM8vz/8pdc2906F6ie+X+fkmHqq6qlvfSnIx+rqtMcYYwQAAGCpGLcLAAAA6AjCDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAqxFmAACA1bq7XUBnq6+v14kTJ5SQkCCPx+N2OQAAoA2MMaqurlZqaqpiYlq+99Llw8yJEyeUlpbmdhkAACACn376qQYNGtTiNl0+zCQkJEj6thmJiYkuV+OMYDCorVu3Kjc3V7GxsW6XYz366Sz66Sz66Sz66azO7GdVVZXS0tJCP8db0uXDTMNLS4mJiV0qzMTHxysxMZG/jA6gn86in86in86in846F/1syyMiPAAMAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAAKxGmAEAAFYjzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsFp3twtA5DL9WxSo87R7v6PLp3ZCNQAAuIM7MwAAwGqEGQAAYDXCDAAAsBphBgAAWI0wAwAArMa7mWCFIT97M+J9efcWAHRt3JkBAABWI8wAAACrEWYAAIDVXA0zfr9fHo8n7Mvn84XWG2Pk9/uVmpqquLg4TZw4UYcOHXKxYgAAEG1cvzNz8cUXq6ysLPRVWloaWrdixQoVFBSosLBQJSUl8vl8ysnJUXV1tYsVAwCAaOL6u5m6d+8edjemgTFGK1eu1OLFizVr1ixJ0tq1a5WcnKx169Zp3rx5Tc4XCAQUCARCy1VVVZKkYDCoYDDYCWdw7jWchzfGdGh/m3i7RXauUuvn27Dexr5EI/rpLPrpLPrprM7sZ3vm9BhjIv8p0UF+v1+/+tWvlJSUJK/Xq/Hjxys/P18XXnihPv74Yw0dOlTvvvuuxowZE9pnxowZ6t27t9auXdvsnEuXLm00vm7dOsXHx3fauQAAAOfU1NRozpw5OnnypBITE1vc1tUws2nTJtXU1Gj48OH6/PPP9eSTT+qvf/2rDh06pMOHD+vKK6/U8ePHlZqaGtrnnnvu0bFjx7Rly5Ym52zqzkxaWpq++OKLVpthi2AwqKKiIj22N0aB+vZ/avZB/+ROqKpzZfqb/vNui9bOt6GfOTk5io2Njfg4+Bb9dBb9dBb9dFZn9rOqqkr9+/dvU5hx9WWmKVOmhL6/5JJLlJ2draFDh2rt2rW64oorJEkeT/gPa2NMo7Hv8nq98nq9jcZjY2O73IUbqPcoUNf+MGNjHyI5zwZtPd+ueI24iX46i346i346qzP62Z75XH8A+Lt69uypSy65RB988EHoOZry8vKwbSoqKpScnOxGeQAAIApFVZgJBAJ6//33lZKSovT0dPl8PhUVFYXW19bWqri4WBMmTHCxSgAAEE1cfZnpH/7hHzR9+nRdcMEFqqio0JNPPqmqqirl5eXJ4/FowYIFys/PV0ZGhjIyMpSfn6/4+HjNmTPHzbIBAEAUcTXMfPbZZ/rxj3+sL774QgMGDNAVV1yhPXv2aPDgwZKkRx55RKdPn9b999+vyspKjR8/Xlu3blVCQoKbZQMAgCjiaphZv359i+s9Ho/8fr/8fv+5KQgAAFgnqp6ZAQAAaC/CDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAqxFmAACA1QgzAADAaoQZAABgNcIMAACwGmEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFitu9sF4IdjyM/edLsEAEAXxJ0ZAABgNcIMAACwGmEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAAKxGmAEAAFYjzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAqxFmAACA1QgzAADAaoQZAABgNcIMAACwGmEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAAKwWNWFm2bJl8ng8WrBgQWjMGCO/36/U1FTFxcVp4sSJOnTokHtFAgCAqBMVYaakpEQvvviiRo0aFTa+YsUKFRQUqLCwUCUlJfL5fMrJyVF1dbVLlQIAgGjjepj55ptvdOutt+p3v/ud+vTpExo3xmjlypVavHixZs2apczMTK1du1Y1NTVat26dixUDAIBo0t3tAh544AFNnTpV119/vZ588snQ+JEjR1ReXq7c3NzQmNfr1TXXXKPdu3dr3rx5Tc4XCAQUCARCy1VVVZKkYDCoYDDYSWdxbjWchzfGdGj/c83bLbJ6O6q1821Y31WuD7fRT2fRT2fRT2d1Zj/bM6erYWb9+vV69913VVJS0mhdeXm5JCk5OTlsPDk5WceOHWt2zmXLlmnp0qWNxrdu3ar4+PgOVhxdfpFVH9F+GzdudLiStllxuSuHbfP5FhUVdXIlPyz001n001n001md0c+ampo2b+tamPn000/18MMPa+vWrTrvvPOa3c7j8YQtG2MajX3XokWLtHDhwtByVVWV0tLSlJubq8TExI4XHgWCwaCKior02N4YBeqb70VzDvond0JVrcv0b3HluK2db0M/c3JyFBsbe46q6rrop7Pop7Pop7M6s58Nr6y0hWthZt++faqoqNDYsWNDY3V1ddq5c6cKCwt1+PBhSd/eoUlJSQltU1FR0ehuzXd5vV55vd5G47GxsV3uwg3UexSoa3+YcasPkdTqhLaeb1e8RtxEP51FP51FP53VGf1sz3yuPQB83XXXqbS0VPv37w99ZWVl6dZbb9X+/ft14YUXyufzhd26qq2tVXFxsSZMmOBW2QAAIMq4dmcmISFBmZmZYWM9e/ZUv379QuMLFixQfn6+MjIylJGRofz8fMXHx2vOnDlulAwAAKKQ6+9maskjjzyi06dP6/7771dlZaXGjx+vrVu3KiEhwe3SAABAlIiqMLNjx46wZY/HI7/fL7/f70o9AAAg+rn+S/MAAAA6gjADAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAAKxGmAEAAFYjzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAq3V3uwCce0N+9mbE+x5dPtXBSgAA6DjuzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWI23Zrso0rdIe7sZrbjc4WIAALAUd2YAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAAKxGmAEAAFYjzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBofNIl2ifTDMQEA6CzcmQEAAFYjzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAqxFmAACA1QgzAADAaoQZAABgNcIMAACwGmEGAABYjTADAACs5mqYee655zRq1CglJiYqMTFR2dnZ2rRpU2i9MUZ+v1+pqamKi4vTxIkTdejQIRcrBgAA0cbVMDNo0CAtX75ce/fu1d69ezVp0iTNmDEjFFhWrFihgoICFRYWqqSkRD6fTzk5OaqurnazbAAAEEVcDTPTp0/XjTfeqOHDh2v48OH65S9/qV69emnPnj0yxmjlypVavHixZs2apczMTK1du1Y1NTVat26dm2UDAIAo0t3tAhrU1dXpP/7jP3Tq1CllZ2fryJEjKi8vV25ubmgbr9era665Rrt379a8efOanCcQCCgQCISWq6qqJEnBYFDBYLBzT6KdvN1MZPvFmLD/omWt/bk3rI+268NW9NNZ9NNZ9NNZndnP9szpMca0+yfihRdeqJKSEvXr1y9s/Ouvv9Zll12mjz/+uM1zlZaWKjs7W2fOnFGvXr20bt063Xjjjdq9e7euvPJKHT9+XKmpqaHt77nnHh07dkxbtmxpcj6/36+lS5c2Gl+3bp3i4+PbXBcAAHBPTU2N5syZo5MnTyoxMbHFbSO6M3P06FHV1dU1Gg8EAjp+/Hi75hoxYoT279+vr7/+Wq+88ory8vJUXFwcWu/xeMK2N8Y0GvuuRYsWaeHChaHlqqoqpaWlKTc3t9VmnGuZ/qYDWWu8MUa/yKrXY3tjFKhvvhf41kH/5BbXB4NBFRUVKScnR7Gxseeoqq6LfjqLfjqLfjqrM/vZ8MpKW7QrzLzxxhuh77ds2aKkpKTQcl1dnd5++20NGTKkPVOqR48eGjZsmCQpKytLJSUleuaZZ/RP//RPkqTy8nKlpKSEtq+oqFBycnKz83m9Xnm93kbjsbGxUXfhBuo6FkQC9Z4Oz/FD0NY/92i8RmxGP51FP51FP53VGf1sz3ztCjMzZ86U9O3dkry8vEYHHTJkiJ5++un2TNmIMUaBQEDp6eny+XwqKirSmDFjJEm1tbUqLi7WU0891aFjAACArqNdYaa+vl6SlJ6erpKSEvXv379DB3/00Uc1ZcoUpaWlqbq6WuvXr9eOHTu0efNmeTweLViwQPn5+crIyFBGRoby8/MVHx+vOXPmdOi4AACg64jomZkjR444cvDPP/9ct99+u8rKypSUlKRRo0Zp8+bNysnJkSQ98sgjOn36tO6//35VVlZq/Pjx2rp1qxISEhw5PgAAsF/Eb81+++239fbbb6uioiJ0x6bBqlWr2jTH73//+xbXezwe+f1++f3+SMsEAABdXERhZunSpXriiSeUlZWllJSUFt9dBAAA0JkiCjPPP/+81qxZo9tvv93pegAAANoloo8zqK2t1YQJE5yuBQAAoN0iCjN33XUXn48EAACiQkQvM505c0Yvvvii3nrrLY0aNarRL7YpKChwpDgAAIDWRBRmDhw4oEsvvVSSdPDgwbB1PAwMAADOpYjCzPbt252uAwAAICIRPTMDAAAQLSK6M3Pttde2+HLStm3bIi4IAACgPSIKMw3PyzQIBoPav3+/Dh482OgDKAEAADpTRGHm17/+dZPjfr9f33zzTYcKAgAAaA9Hn5m57bbb2vy5TAAAAE5wNMz893//t8477zwnpwQAAGhRRC8zzZo1K2zZGKOysjLt3btXjz32mCOFAQAAtEVEYSYpKSlsOSYmRiNGjNATTzyh3NxcRwoDAABoi4jCzOrVq52uAwAAICIRhZkG+/bt0/vvvy+Px6ORI0dqzJgxTtUFAADQJhGFmYqKCt1yyy3asWOHevfuLWOMTp48qWuvvVbr16/XgAEDnK4TAACgSRG9m+nBBx9UVVWVDh06pK+++kqVlZU6ePCgqqqq9NBDDzldIwAAQLMiujOzefNmvfXWW7roootCYyNHjtRvf/tbHgAGAADnVER3Zurr6xUbG9toPDY2VvX19R0uCgAAoK0iCjOTJk3Sww8/rBMnToTGjh8/rp/85Ce67rrrHCsOAACgNRGFmcLCQlVXV2vIkCEaOnSohg0bpvT0dFVXV+s3v/mN0zUCAAA0K6JnZtLS0vTuu++qqKhIf/3rX2WM0ciRI3X99dc7XR8AAECL2nVnZtu2bRo5cqSqqqokSTk5OXrwwQf10EMPady4cbr44ou1a9euTikUAACgKe0KMytXrtTdd9+txMTERuuSkpI0b948FRQUOFYcAABAa9oVZv785z/rhhtuaHZ9bm6u9u3b1+GiAAAA2qpdYebzzz9v8i3ZDbp3767//d//7XBRAAAAbdWuMHP++eertLS02fUHDhxQSkpKh4sCAABoq3aFmRtvvFGPP/64zpw502jd6dOntWTJEk2bNs2x4gAAAFrTrrdm//znP9eGDRs0fPhwzZ8/XyNGjJDH49H777+v3/72t6qrq9PixYs7q1YAAIBG2hVmkpOTtXv3bt13331atGiRjDGSJI/Ho8mTJ+vZZ59VcnJypxQKAADQlHb/0rzBgwdr48aNqqys1IcffihjjDIyMtSnT5/OqA8AAKBFEf0GYEnq06ePxo0b52QtAAAA7RbRZzMBAABEC8IMAACwGmEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAAKxGmAEAAFYjzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWI0wAwAArNbd7QJsN+Rnb7pdAlrR2p+Rt5vRisulTP8WBeo8YeuOLp/amaUBABzAnRkAAGA1wgwAALCaq2Fm2bJlGjdunBISEjRw4EDNnDlThw8fDtvGGCO/36/U1FTFxcVp4sSJOnTokEsVAwCAaONqmCkuLtYDDzygPXv2qKioSGfPnlVubq5OnToV2mbFihUqKChQYWGhSkpK5PP5lJOTo+rqahcrBwAA0cLVB4A3b94ctrx69WoNHDhQ+/bt09VXXy1jjFauXKnFixdr1qxZkqS1a9cqOTlZ69at07x58xrNGQgEFAgEQstVVVWSpGAwqGAw6Pg5eLsZx+ds9ZgxJuy/6JiW+tkZ10xX19AzeucM+uks+umszuxne+b0GGOi5ifihx9+qIyMDJWWliozM1Mff/yxhg4dqnfffVdjxowJbTdjxgz17t1ba9eubTSH3+/X0qVLG42vW7dO8fHxnVo/AABwRk1NjebMmaOTJ08qMTGxxW2jJswYYzRjxgxVVlZq165dkqTdu3fryiuv1PHjx5Wamhra9p577tGxY8e0ZcuWRvM0dWcmLS1NX3zxRavNiESmv3ENnc0bY/SLrHo9tjdGgXpP6zugRS3186B/sktV2SsYDKqoqEg5OTmKjY11uxzr0U9n0U9ndWY/q6qq1L9//zaFmaj5PTPz58/XgQMH9M477zRa5/GE/4AxxjQaa+D1euX1ehuNx8bGdsqF+/3fS3IuBeo9rh6/q2mqn/xjF7nO+jv3Q0U/nUU/ndUZ/WzPfFHx1uwHH3xQb7zxhrZv365BgwaFxn0+nySpvLw8bPuKigolJyef0xoBAEB0cjXMGGM0f/58bdiwQdu2bVN6enrY+vT0dPl8PhUVFYXGamtrVVxcrAkTJpzrcgEAQBRy9WWmBx54QOvWrdPrr7+uhISE0B2YpKQkxcXFyePxaMGCBcrPz1dGRoYyMjKUn5+v+Ph4zZkzx83SAQBAlHA1zDz33HOSpIkTJ4aNr169WnfccYck6ZFHHtHp06d1//33q7KyUuPHj9fWrVuVkJBwjqsFAADRyNUw05Y3Unk8Hvn9fvn9/s4vCAAAWCcqHgAGAACIFGEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAAKxGmAEAAFYjzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAqxFmAACA1QgzAADAaoQZAABgNcIMAACwGmEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAAKxGmAEAAFYjzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAqxFmAACA1QgzAADAaoQZAABgNcIMAACwGmEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGA1V8PMzp07NX36dKWmpsrj8ei1114LW2+Mkd/vV2pqquLi4jRx4kQdOnTInWIBAEBUcjXMnDp1SqNHj1ZhYWGT61esWKGCggIVFhaqpKREPp9POTk5qq6uPseVAgCAaNXdzYNPmTJFU6ZMaXKdMUYrV67U4sWLNWvWLEnS2rVrlZycrHXr1mnevHnnslQAABClXA0zLTly5IjKy8uVm5sbGvN6vbrmmmu0e/fuZsNMIBBQIBAILVdVVUmSgsGggsGg43V6uxnH52z1mDEm7L/omJb62RnXTFfX0DN65wz66Sz66azO7Gd75ozaMFNeXi5JSk5ODhtPTk7WsWPHmt1v2bJlWrp0aaPxrVu3Kj4+3tkiJa243PEp2+wXWfXuHbwLaqqfGzdudKGSrqGoqMjtEroU+uks+umszuhnTU1Nm7eN2jDTwOPxhC0bYxqNfdeiRYu0cOHC0HJVVZXS0tKUm5urxMREx+vL9G9xfM7WeGOMfpFVr8f2xihQ33wv0DYt9fOgf7JLVdkrGAyqqKhIOTk5io2Ndbsc69FPZ9FPZ3VmPxteWWmLqA0zPp9P0rd3aFJSUkLjFRUVje7WfJfX65XX6200Hhsb2ykXbqDOvTARqPe4evyupql+8o9d5Drr79wPFf10Fv10Vmf0sz3zRe3vmUlPT5fP5wu7dVVbW6vi4mJNmDDBxcoAAEA0cfXOzDfffKMPP/wwtHzkyBHt379fffv21QUXXKAFCxYoPz9fGRkZysjIUH5+vuLj4zVnzhwXqwYAANHE1TCzd+9eXXvttaHlhmdd8vLytGbNGj3yyCM6ffq07r//flVWVmr8+PHaunWrEhIS3CoZAABEGVfDzMSJE2VM828v9ng88vv98vv9564oAABglah9ZgYAAKAtCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAAKxGmAEAAFYjzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAqxFmAACA1QgzAADAaoQZAABgNcIMAACwGmEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAAKxGmAEAAFYjzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAq3V3uwAAAOCuIT97M6L9vN2MVlzucDER4M4MAACwGmEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVeGs20IJI364oSUeXT3WwEgBAc7gzAwAArEaYAQAAViPMAAAAqxFmAACA1QgzAADAaoQZAABgNcIMAACwGmEGAABYjTADAACsZkWYefbZZ5Wenq7zzjtPY8eO1a5du9wuCQAARImoDzP//u//rgULFmjx4sV67733dNVVV2nKlCn65JNP3C4NAABEgagPMwUFBbrzzjt111136aKLLtLKlSuVlpam5557zu3SAABAFIjqD5qsra3Vvn379LOf/SxsPDc3V7t3725yn0AgoEAgEFo+efKkJOmrr75SMBh0vMbuZ085Pmerx6w3qqmpV/dgjOrqPef8+F1NZ/Xzyy+/dGwumwSDQdXU1OjLL79UbGys2+VYj346i342LdKfZQ3/fnZGP6urqyVJxpjW63D0yA774osvVFdXp+Tk5LDx5ORklZeXN7nPsmXLtHTp0kbj6enpnVKjW+a4XUAX0xn97P90J0wKAFGms38eVVdXKykpqcVtojrMNPB4wv9v2RjTaKzBokWLtHDhwtByfX29vvrqK/Xr16/ZfWxTVVWltLQ0ffrpp0pMTHS7HOvRT2fRT2fRT2fRT2d1Zj+NMaqurlZqamqr20Z1mOnfv7+6devW6C5MRUVFo7s1Dbxer7xeb9hY7969O6tEVyUmJvKX0UH001n001n001n001md1c/W7sg0iOoHgHv06KGxY8eqqKgobLyoqEgTJkxwqSoAABBNovrOjCQtXLhQt99+u7KyspSdna0XX3xRn3zyie699163SwMAAFEg6sPM7Nmz9eWXX+qJJ55QWVmZMjMztXHjRg0ePNjt0lzj9Xq1ZMmSRi+nITL001n001n001n001nR0k+Pact7ngAAAKJUVD8zAwAA0BrCDAAAsBphBgAAWI0wAwAArEaYiWJ+v18ejyfsy+fzhdYbY+T3+5Wamqq4uDhNnDhRhw4dcrHi6LJz505Nnz5dqamp8ng8eu2118LWt6V/gUBADz74oPr376+ePXvqpptu0meffXYOzyJ6tNbPO+64o9H1esUVV4RtQz+/tWzZMo0bN04JCQkaOHCgZs6cqcOHD4dtw/XZdm3pJ9dn2z333HMaNWpU6BfhZWdna9OmTaH10XhtEmai3MUXX6yysrLQV2lpaWjdihUrVFBQoMLCQpWUlMjn8yknJyf04Vw/dKdOndLo0aNVWFjY5Pq29G/BggV69dVXtX79er3zzjv65ptvNG3aNNXV1Z2r04garfVTkm644Yaw63Xjxo1h6+nnt4qLi/XAAw9oz549Kioq0tmzZ5Wbm6tTp/7vw/64PtuuLf2UuD7batCgQVq+fLn27t2rvXv3atKkSZoxY0YosETltWkQtZYsWWJGjx7d5Lr6+nrj8/nM8uXLQ2NnzpwxSUlJ5vnnnz9HFdpDknn11VdDy23p39dff21iY2PN+vXrQ9scP37cxMTEmM2bN5+z2qPR9/tpjDF5eXlmxowZze5DP5tXUVFhJJni4mJjDNdnR32/n8ZwfXZUnz59zL/+679G7bXJnZko98EHHyg1NVXp6em65ZZb9PHHH0uSjhw5ovLycuXm5oa29Xq9uuaaa7R79263yrVGW/q3b98+BYPBsG1SU1OVmZlJj5uxY8cODRw4UMOHD9fdd9+tioqK0Dr62byTJ09Kkvr27SuJ67Ojvt/PBlyf7VdXV6f169fr1KlTys7OjtprkzATxcaPH68//OEP2rJli373u9+pvLxcEyZM0Jdffhn68M3vf+BmcnJyow/mRGNt6V95ebl69OihPn36NLsN/s+UKVP00ksvadu2bXr66adVUlKiSZMmKRAISKKfzTHGaOHChfq7v/s7ZWZmSuL67Iim+ilxfbZXaWmpevXqJa/Xq3vvvVevvvqqRo4cGbXXZtR/nMEP2ZQpU0LfX3LJJcrOztbQoUO1du3a0INrHo8nbB9jTKMxNC+S/tHjps2ePTv0fWZmprKysjR48GC9+eabmjVrVrP7/dD7OX/+fB04cEDvvPNOo3Vcn+3XXD+5PttnxIgR2r9/v77++mu98sorysvLU3FxcWh9tF2b3JmxSM+ePXXJJZfogw8+CL2r6fspt6KiolFiRmNt6Z/P51Ntba0qKyub3QbNS0lJ0eDBg/XBBx9Iop9NefDBB/XGG29o+/btGjRoUGic6zMyzfWzKVyfLevRo4eGDRumrKwsLVu2TKNHj9YzzzwTtdcmYcYigUBA77//vlJSUpSeni6fz6eioqLQ+traWhUXF2vChAkuVmmHtvRv7Nixio2NDdumrKxMBw8epMdt8OWXX+rTTz9VSkqKJPr5XcYYzZ8/Xxs2bNC2bduUnp4etp7rs31a62dTuD7bxxijQCAQvddmpzxWDEf89Kc/NTt27DAff/yx2bNnj5k2bZpJSEgwR48eNcYYs3z5cpOUlGQ2bNhgSktLzY9//GOTkpJiqqqqXK48OlRXV5v33nvPvPfee0aSKSgoMO+99545duyYMaZt/bv33nvNoEGDzFtvvWXeffddM2nSJDN69Ghz9uxZt07LNS31s7q62vz0pz81u3fvNkeOHDHbt2832dnZ5vzzz6efTbjvvvtMUlKS2bFjhykrKwt91dTUhLbh+my71vrJ9dk+ixYtMjt37jRHjhwxBw4cMI8++qiJiYkxW7duNcZE57VJmIlis2fPNikpKSY2NtakpqaaWbNmmUOHDoXW19fXmyVLlhifz2e8Xq+5+uqrTWlpqYsVR5ft27cbSY2+8vLyjDFt69/p06fN/PnzTd++fU1cXJyZNm2a+eSTT1w4G/e11M+amhqTm5trBgwYYGJjY80FF1xg8vLyGvWKfn6rqT5KMqtXrw5tw/XZdq31k+uzfebOnWsGDx5sevToYQYMGGCuu+66UJAxJjqvTY8xxnTOPR8AAIDOxzMzAADAaoQZAABgNcIMAACwGmEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVCDPAD5jf79ell14aWr7jjjs0c+ZM1+rpiDVr1qh3796uHf/3v/+9cnNzOzTH0aNH5fF4tH///jbvU1hYqJtuuqlDxwVsR5gBLHPHHXfI4/HI4/EoNjZWycnJysnJ0apVq1RfX9+huZ955hmtWbPGmUIdNGTIkNA5N/U1ceJEzZ49W3/7299cqS8QCOjxxx/XY4891qF50tLSVFZWpszMzDbvc/fdd6ukpETvvPNOh44N2IwwA1johhtuUFlZmY4ePapNmzbp2muv1cMPP6xp06bp7NmzEc+blJTU6Xc3gsFgu/cpKSlRWVmZysrK9Morr0iSDh8+HBrbsGGD4uLiNHDgQKfLbZNXXnlFvXr10lVXXdWhebp16yafz6fu3bu3eR+v16s5c+boN7/5TYeODdiMMANYyOv1yufz6fzzz9dll12mRx99VK+//ro2bdoUdmfl5MmTuueeezRw4EAlJiZq0qRJ+vOf/9zsvN99memFF17Q+eef3+huz0033aS8vLzQ8n/+539q7NixOu+883ThhRdq6dKlYYHK4/Ho+eef14wZM9SzZ089+eSTGjZsmP75n/85bN6DBw8qJiZGH330UaO6BgwYIJ/PJ5/Pp759+0qSBg4cGDb2/ZeZGl5CW7VqlS644AL16tVL9913n+rq6rRixQr5fD4NHDhQv/zlL8OO1d6eSdL69esbvdTT0Mv8/HwlJyerd+/eod784z/+o/r27atBgwZp1apVoX2+/zLTjh075PF49PbbbysrK0vx8fGaMGGCDh8+3OjP5LXXXtPp06dbrBPoqggzQBcxadIkjR49Whs2bJAkGWM0depUlZeXa+PGjdq3b58uu+wyXXfddfrqq69ane/mm2/WF198oe3bt4fGKisrtWXLFt16662SpC1btui2227TQw89pL/85S964YUXtGbNmkYBYcmSJZoxY4ZKS0s1d+5czZ07V6tXrw7bZtWqVbrqqqs0dOjQjrYi5KOPPtKmTZu0efNmvfzyy1q1apWmTp2qzz77TMXFxXrqqaf085//XHv27JEUec927dqlrKysRuPbtm3TiRMntHPnThUUFMjv92vatGnq06eP/vSnP+nee+/Vvffeq08//bTF81i8eLGefvpp7d27V927d9fcuXPD1mdlZSkYDOp//ud/IugS0AV02udxA+gUeXl5ZsaMGU2umz17trnooouMMca8/fbbJjEx0Zw5cyZsm6FDh5oXXnjBGGPMkiVLzOjRo5ud+6abbjJz584NLb/wwgvG5/OZs2fPGmOMueqqq0x+fn7Y/P/2b/9mUlJSQsuSzIIFC8K2OXHihOnWrZv505/+ZIwxpra21gwYMMCsWbOm1fPfvn27kWQqKyvDxlevXm2SkpJCy0uWLDHx8fGmqqoqNDZ58mQzZMgQU1dXFxobMWKEWbZsmTGmbT37vsrKSiPJ7Ny5M2w8Ly/PDB48uNGxrrrqqtDy2bNnTc+ePc3LL79sjDHmyJEjRpJ57733ws71rbfeCu3z5ptvGknm9OnTYcfr06dPm/oHdEVtf2EWQNQzxsjj8UiS9u3bp2+++Ub9+vUL2+b06dNNvpTTlFtvvVX33HOPnn32WXm9Xr300ku65ZZb1K1bt9AxSkpKwu7E1NXV6cyZM6qpqVF8fLwkNbprkZKSoqlTp2rVqlW6/PLL9cc//lFnzpzRzTffHPG5N2XIkCFKSEgILScnJ6tbt26KiYkJG6uoqAidT3t71vDSznnnnddo3cUXX9zoWN99uLdbt27q169f6PjNGTVqVOj7lJQUSVJFRYUuuOCC0HhcXJxqampanAfoqggzQBfy/vvvKz09XZJUX1+vlJQU7dixo9F2bX3Id/r06aqvr9ebb76pcePGadeuXSooKAitr6+v19KlSzVr1qxG+373h3vPnj0brb/rrrt0++2369e//rVWr16t2bNnh8KPU2JjY8OWG94B9v2xhueCIulZv3795PF4VFlZ2eHjt+U8GsLq9/f56quvNGDAgBbnAboqwgzQRWzbtk2lpaX6yU9+Ikm67LLLVF5eru7du2vIkCERzRkXF6dZs2bppZde0ocffqjhw4dr7NixofWXXXaZDh8+rGHDhrV77htvvFE9e/bUc889p02bNmnnzp0R1eikSHrWo0cPjRw5Un/5y186/HtmIvXRRx/pzJkzGjNmjCvHB9xGmAEsFAgEVF5errq6On3++efavHmzli1bpmnTpunv//7vJUnXX3+9srOzNXPmTD311FMaMWKETpw4oY0bN2rmzJlNPrDalFtvvVXTp0/XoUOHdNttt4Wte/zxxzVt2jSlpaXp5ptvVkxMjA4cOKDS0lI9+eSTLc7brVs33XHHHVq0aJGGDRum7OzsyJrhoEh7NnnyZL3zzjtasGDBuS34/9u1a5cuvPBCRx+eBmzCu5kAC23evFkpKSkaMmSIbrjhBm3fvl3/8i//otdffz30PIvH49HGjRt19dVXa+7cuRo+fLhuueUWHT16VMnJyW0+1qRJk9S3b18dPnxYc+bMCVs3efJk/fGPf1RRUZHGjRunK664QgUFBRo8eHCb5r7zzjtVW1vb6N05bom0Z3fffbc2btyokydPnsNq/8/LL7+su+++25VjA9HAY4wxbhcB4Ifpv/7rvzRx4kR99tln7QpY0ehHP/qRxowZo0WLFp3T4x48eFDXXXed/va3vykpKemcHhuIFtyZAXDOBQIBffjhh3rsscf0ox/9yPogI0m/+tWv1KtXr3N+3BMnTugPf/gDQQY/aNyZAXDOrVmzRnfeeacuvfRSvfHGGzr//PPdLgmAxQgzAADAarzMBAAArEaYAQAAViPMAAAAqxFmAACA1QgzAADAaoQZAABgNcIMAACwGmEGAABY7f8BwzrZdA0e1wwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"delivery_time_min\"].hist(bins=30)\n",
    "plt.xlabel(\"Delivery Time (min)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22541c24-2116-4176-a060-983012a134f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "What notes you MUST write (only these)\n",
    "Write this on one page:\n",
    "1.\tmean vs median (median safer with outliers)\n",
    "2.\tstd = spread\n",
    "3.\tpercentiles (90%, 99%) for boundaries\n",
    "4.\tZ-score: (x − mean) / std\n",
    "5.\tMin-max: (x − min) / (max − min)\n",
    "6.\tCosine similarity: dot(a,b) / (||a||·||b||)\n",
    "That’s your “Module 1 brain”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee63d4e1-3ec6-40a3-9bd8-1cf5ddf72de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Module 2 — Linear Algebra for AI (with a real project)\n",
    "\n",
    "Why we need this in AI (simple truth)\n",
    "\n",
    "In AI, everything becomes a vector (list of numbers):\n",
    "•\tan image → vector of pixel values (or features)\n",
    "•\ta sentence → embedding vector (e.g., 768 numbers)\n",
    "•\ta user profile → vector of behavior features\n",
    "Models are mostly matrix multiplications:\n",
    "•\tneural net layer = X @ W + b\n",
    "•\tattention = Q @ K.T then softmax, then @ V\n",
    "•\tPCA = rotate/transform data to a better coordinate system\n",
    "So you learn linear algebra to answer:\n",
    "•\t“What is the shape?”\n",
    "•\t“Why is this multiply possible?”\n",
    "•\t“Why does scaling/rotation change results?”\n",
    "•\t“How do embeddings similarity and compression work?”\n",
    "________________________________________\n",
    "Core topics you must learn in Module 2\n",
    "\n",
    "1) Shapes (most important skill)\n",
    "•\tscalar: ()\n",
    "•\tvector: (d,)\n",
    "•\tmatrix: (n, d)\n",
    "•\t“dataset”: X is usually (n_samples, n_features)\n",
    "2) Vector ops\n",
    "•\tadd/subtract, multiply by scalar\n",
    "•\tdot product\n",
    "•\tnorm (length)\n",
    "3) Matrix ops\n",
    "•\ttranspose\n",
    "•\tmatrix multiply (@)\n",
    "•\twhy shapes must match\n",
    "4) Projection intuition\n",
    "•\tprojecting onto a direction = “keep only what matters along that direction”\n",
    "5) PCA using SVD\n",
    "•\tSVD is the safest practical way\n",
    "•\tPCA compresses dimensions while keeping most signal\n",
    "________________________________________\n",
    "Real-world AI Project (best practical one)\n",
    "\n",
    "Project: Compress embeddings using PCA and check that search still works\n",
    "\n",
    "This is exactly what happens in:\n",
    "•\tretrieval systems (search)\n",
    "•\tvector databases / embeddings storage optimization\n",
    "•\tspeeding up similarity search\n",
    "We’ll make:\n",
    "1.\ta fake “embedding dataset” (like 50-dim vectors)\n",
    "2.\tcompress it to 10 dims using PCA\n",
    "3.\trun cosine-similarity search in both\n",
    "4.\tcompare how many “top results” overlap\n",
    "________________________________________\n",
    "Step 1 — Create “embedding-like” data\n",
    "\n",
    "Why\n",
    "Real embeddings have structure (not random noise). So we generate data with hidden factors.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "n = 800     # number of items (documents/products)\n",
    "d = 50      # original embedding dimension\n",
    "k_true = 6  # hidden factors (real structure)\n",
    "\n",
    "# Hidden factor representation (n x k_true)\n",
    "Z = np.random.randn(n, k_true)\n",
    "\n",
    "# Random mixing matrix to create embeddings (k_true x d)\n",
    "A = np.random.randn(k_true, d)\n",
    "\n",
    "# Embeddings (n x d) with a bit of noise\n",
    "X = Z @ A + 0.2 * np.random.randn(n, d)\n",
    "\n",
    "print(\"X shape:\", X.shape)  # should be (800, 50)\n",
    "What you learned:\n",
    "X is a matrix: 800 items, each has 50 numbers.\n",
    "________________________________________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0900f4-f997-4edd-adfd-8bcfee5da139",
   "metadata": {},
   "outputs": [],
   "source": [
    "Step 2 — Tiny linear algebra essentials (dot, norm, cosine)\n",
    "\n",
    "Why\n",
    "Cosine similarity is used for embeddings search everywhere.\n",
    "def cosine_sim_matrix(A, b):\n",
    "    \"\"\"\n",
    "    A: (n, d)\n",
    "    b: (d,)\n",
    "    returns: (n,) cosine similarities\n",
    "    \"\"\"\n",
    "    num = A @ b                      # dot with each row (n,)\n",
    "    den = np.linalg.norm(A, axis=1) * np.linalg.norm(b)\n",
    "    return num / den\n",
    "\n",
    "# test: pick one vector and compare with all\n",
    "idx = 10\n",
    "sims = cosine_sim_matrix(X, X[idx])\n",
    "print(\"Most similar index should be itself:\", np.argmax(sims))\n",
    "Why A @ b works:\n",
    "A has rows (vectors). Dot product with b gives similarity signal.\n",
    "________________________________________\n",
    "Step 3 — PCA using SVD (the real tool)\n",
    "\n",
    "Why PCA\n",
    "Embeddings might be 768 dims, 1536 dims, etc. PCA can compress while keeping signal.\n",
    "Why SVD\n",
    "Numerically stable and standard.\n",
    "PCA steps (must memorize):\n",
    "1.\tcenter the data: Xc = X - mean\n",
    "2.\tdo SVD: Xc = U S Vᵀ\n",
    "3.\ttake first k directions from Vᵀ\n",
    "4.\tproject: Xk = Xc @ Vk\n",
    "# 1) Center\n",
    "X_mean = X.mean(axis=0)\n",
    "Xc = X - X_mean\n",
    "\n",
    "# 2) SVD\n",
    "U, S, Vt = np.linalg.svd(Xc, full_matrices=False)\n",
    "\n",
    "# Explained variance ratio (how much signal each component holds)\n",
    "explained = (S**2) / np.sum(S**2)\n",
    "\n",
    "print(\"Top 10 variance ratios:\", explained[:10])\n",
    "print(\"Variance captured by first 10:\", explained[:10].sum())\n",
    "\n",
    "# 3) Choose reduced dimension\n",
    "k = 10\n",
    "Vk = Vt[:k].T          # (d x k)\n",
    "\n",
    "# 4) Project to k dims\n",
    "Xk = Xc @ Vk           # (n x k)\n",
    "print(\"Reduced shape:\", Xk.shape)\n",
    "What you learned (super important):\n",
    "•\tVt[:k] are the top “directions” (principal components)\n",
    "•\tmultiplying Xc @ Vk gives compressed embeddings\n",
    "________________________________________\n",
    "Step 4 — Search before vs after compression\n",
    "\n",
    "Why\n",
    "We want to know if PCA compression keeps “nearest neighbors” similar.\n",
    "def top_k_indices(sim, topk=10):\n",
    "    return np.argsort(sim)[-topk:][::-1]\n",
    "\n",
    "query_idx = 123\n",
    "q_original = X[query_idx]\n",
    "q_reduced  = Xk[query_idx]\n",
    "\n",
    "# Similarity search in original space\n",
    "sim_orig = cosine_sim_matrix(X, q_original)\n",
    "top_orig = top_k_indices(sim_orig, topk=10)\n",
    "\n",
    "# Similarity search in reduced space\n",
    "sim_red = cosine_sim_matrix(Xk, q_reduced)\n",
    "top_red = top_k_indices(sim_red, topk=10)\n",
    "\n",
    "overlap = len(set(top_orig) & set(top_red))\n",
    "\n",
    "print(\"Top-10 overlap count:\", overlap)\n",
    "print(\"Original top-10:\", top_orig)\n",
    "print(\"Reduced  top-10:\", top_red)\n",
    "Interpretation (Babu-friendly):\n",
    "•\tOverlap close to 10 = compression kept search results almost same\n",
    "•\tOverlap low = too much info lost (k too small)\n",
    "________________________________________\n",
    "Step 5 — Pick the best k (tiny experiment)\n",
    "\n",
    "Why\n",
    "This is what AI engineers actually do: choose compression based on tradeoff.\n",
    "def pca_reduce(X, k):\n",
    "    Xc = X - X.mean(axis=0)\n",
    "    U, S, Vt = np.linalg.svd(Xc, full_matrices=False)\n",
    "    Vk = Vt[:k].T\n",
    "    Xk = Xc @ Vk\n",
    "    explained = (S**2) / np.sum(S**2)\n",
    "    return Xk, explained[:k].sum()\n",
    "\n",
    "ks = [2, 5, 10, 20, 30]\n",
    "for kk in ks:\n",
    "    Xkk, var = pca_reduce(X, kk)\n",
    "    sim_orig = cosine_sim_matrix(X, X[query_idx])\n",
    "    sim_red  = cosine_sim_matrix(Xkk, Xkk[query_idx])\n",
    "    top_orig = top_k_indices(sim_orig, 10)\n",
    "    top_red  = top_k_indices(sim_red, 10)\n",
    "    overlap = len(set(top_orig) & set(top_red))\n",
    "    print(f\"k={kk:2d}  variance={var:.3f}  top10_overlap={overlap}\")\n",
    "You’ll see a pattern:\n",
    "•\thigher k → more variance → better overlap\n",
    "•\tlower k → faster storage/search but more loss\n",
    "\n",
    "The “WHY” behind each key concept (quick, clear)\n",
    "\n",
    "Vector: one item represented as numbers\n",
    "\n",
    "Matrix: many vectors stacked\n",
    "\n",
    "Transpose (.T): flips rows/cols; needed for dot products like Q @ K.T\n",
    "\n",
    "Matrix multiply (@): apply transformations / combine features\n",
    "\n",
    "Projection: keep only certain directions (signal)\n",
    "\n",
    "PCA: find best directions automatically; reduce dimensions\n",
    "\n",
    "SVD: engine that finds those best directions\n",
    "\n",
    "Notes you MUST write (only the useful ones)\n",
    "\n",
    "Shapes rule: (n,d) @ (d,k) → (n,k)\n",
    "\n",
    "Cosine similarity: dot(a,b) / (||a||·||b||)\n",
    "\n",
    "PCA steps: center → SVD → take top k → project\n",
    "\n",
    "Variance captured ≈ “how much info kept”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3019ac3f-8703-431d-af5c-cc3f1eaa991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Module 3 — Calculus + Optimization for AI\n",
    "Why we need this in AI (simple)\n",
    "Training an AI model = minimize a number called loss.\n",
    "•\tLoss is “how wrong the model is”.\n",
    "•\tLearning is “changing parameters so loss goes down”.\n",
    "Calculus gives the gradient (slope direction).\n",
    "Optimization uses that gradient to update weights.\n",
    "Without this, you’ll always feel like: “model trains… but why?”\n",
    "________________________________________\n",
    "Concepts you MUST learn (maximum + practical)\n",
    "A) Function\n",
    "A rule: input → output\n",
    "Example: y = w*x + b\n",
    "B) Loss function\n",
    "A function that measures error.\n",
    "•\tRegression: MSE (mean squared error)\n",
    "•\tClassification: cross-entropy (log loss)\n",
    "C) Derivative (slope)\n",
    "Derivative tells: if I change w a little, how much does loss change?\n",
    "D) Gradient (many slopes)\n",
    "If model has many weights: gradient is a vector of partial derivatives:\n",
    "•\t∂loss/∂w1, ∂loss/∂w2, …\n",
    "E) Gradient Descent (learning rule)\n",
    "Update weights to reduce loss:\n",
    "params = params − learning_rate × gradient\n",
    "F) Learning rate\n",
    "Step size. Too big → explosions. Too small → slow.\n",
    "G) Variants used in real ML\n",
    "•\tBatch GD (uses all data)\n",
    "•\tSGD (one row at a time)\n",
    "•\tMini-batch (best practical default)\n",
    "H) Regularization (avoid overfitting)\n",
    "L2 penalty keeps weights small.\n",
    "________________________________________\n",
    "Real-world project (best practical)\n",
    "Project: “Delivery Delay Risk Predictor” (Binary Classification)\n",
    "We will predict: Will delivery be delayed? (Yes/No)\n",
    "From features:\n",
    "•\tdistance_km\n",
    "•\ttraffic\n",
    "•\train\n",
    "•\tprep_time\n",
    "•\titems\n",
    "Label (target):\n",
    "•\tdelay = 1 if delivery_time > threshold (like 45 min)\n",
    "•\telse 0\n",
    "And we’ll train a Logistic Regression model from scratch using Gradient Descent.\n",
    "This is legit real-world: risk scoring, churn prediction, fraud detection, SLA breach prediction.\n",
    "________________________________________\n",
    "Step 1 — Create realistic data\n",
    "Why\n",
    "You learn best when data looks like real life.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(10)\n",
    "n = 600\n",
    "\n",
    "distance = np.random.uniform(1, 25, n)\n",
    "traffic  = np.random.uniform(0.5, 2.0, n)\n",
    "rain     = np.random.choice([0, 1], size=n, p=[0.8, 0.2])\n",
    "prep     = np.random.normal(12, 4, n).clip(3, 30)\n",
    "items    = np.random.randint(1, 8, n)\n",
    "\n",
    "# Real-ish delivery time (minutes)\n",
    "delivery_time = (\n",
    "    8 + distance*2.5 + traffic*10 + rain*7 + prep*0.9 + items*1.2\n",
    "    + np.random.normal(0, 4, n)\n",
    ")\n",
    "\n",
    "# Binary label: delayed or not (threshold)\n",
    "delay = (delivery_time > 45).astype(int)\n",
    "\n",
    "X = np.column_stack([distance, traffic, rain, prep, items])   # (n,5)\n",
    "y = delay                                                     # (n,)\n",
    "\n",
    "print(\"X shape:\", X.shape, \"y mean (delay rate):\", y.mean())\n",
    "________________________________________\n",
    "Step 2 — Scale features (important for gradient descent)\n",
    "Why\n",
    "Gradient descent hates uneven scales. Scaling makes training stable and fast.\n",
    "mu = X.mean(axis=0)\n",
    "sigma = X.std(axis=0)\n",
    "Xz = (X - mu) / sigma\n",
    "________________________________________\n",
    "Step 3 — Learn the model: Logistic Regression\n",
    "Why logistic regression\n",
    "It outputs probability: P(delay=1).\n",
    "Sigmoid function\n",
    "Turns any number into 0..1 probability.\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "Model:\n",
    "•\tp = sigmoid(X @ w + b)\n",
    "•\tprediction: p > 0.5\n",
    "________________________________________\n",
    "Step 4 — Loss for classification: Cross-Entropy\n",
    "Why not MSE for classification\n",
    "Cross-entropy strongly punishes confident wrong predictions and trains faster.\n",
    "def log_loss(y, p, eps=1e-9):\n",
    "    p = np.clip(p, eps, 1 - eps)\n",
    "    return -np.mean(y*np.log(p) + (1-y)*np.log(1-p))\n",
    "________________________________________\n",
    "Step 5 — Gradients (the calculus part)\n",
    "Why gradients matter\n",
    "Gradient tells the direction to reduce loss.\n",
    "For logistic regression, gradients are:\n",
    "•\tdw = (X.T @ (p - y)) / n\n",
    "•\tdb = mean(p - y)\n",
    "(You don’t need to “prove” this now; you just need to use it correctly.)\n",
    "________________________________________\n",
    "Step 6 — Train with Gradient Descent (with L2 regularization)\n",
    "Why L2 regularization\n",
    "Prevents weights from becoming huge → reduces overfitting.\n",
    "def train_logreg_gd(X, y, lr=0.1, steps=2000, l2=0.0):\n",
    "    n, d = X.shape\n",
    "    w = np.zeros(d)\n",
    "    b = 0.0\n",
    "    losses = []\n",
    "\n",
    "    for t in range(steps):\n",
    "        z = X @ w + b\n",
    "        p = sigmoid(z)\n",
    "\n",
    "        # loss + L2 penalty\n",
    "        loss = log_loss(y, p) + 0.5*l2*np.sum(w*w)\n",
    "        losses.append(loss)\n",
    "\n",
    "        # gradients\n",
    "        err = (p - y)                         # (n,)\n",
    "        dw = (X.T @ err) / n + l2*w            # (d,)\n",
    "        db = err.mean()\n",
    "\n",
    "        # update step\n",
    "        w -= lr * dw\n",
    "        b -= lr * db\n",
    "\n",
    "        if t % 400 == 0:\n",
    "            print(t, \"loss:\", round(loss, 4))\n",
    "\n",
    "    return w, b, np.array(losses)\n",
    "\n",
    "w, b, losses = train_logreg_gd(Xz, y, lr=0.15, steps=2000, l2=0.01)\n",
    "print(\"Trained w:\", w, \"b:\", b)\n",
    "________________________________________\n",
    "Step 7 — Evaluate (accuracy + precision/recall)\n",
    "Why not only accuracy\n",
    "If delays are rare, accuracy can lie. Precision/recall tell truth.\n",
    "def predict_proba(X, w, b):\n",
    "    return sigmoid(X @ w + b)\n",
    "\n",
    "def predict_label(X, w, b, thr=0.5):\n",
    "    return (predict_proba(X, w, b) >= thr).astype(int)\n",
    "\n",
    "def metrics(y_true, y_pred):\n",
    "    tp = np.sum((y_true==1) & (y_pred==1))\n",
    "    tn = np.sum((y_true==0) & (y_pred==0))\n",
    "    fp = np.sum((y_true==0) & (y_pred==1))\n",
    "    fn = np.sum((y_true==1) & (y_pred==0))\n",
    "\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    prec = tp / (tp + fp + 1e-9)\n",
    "    rec = tp / (tp + fn + 1e-9)\n",
    "    return acc, prec, rec, (tp, fp, fn, tn)\n",
    "\n",
    "yhat = predict_label(Xz, w, b, thr=0.5)\n",
    "acc, prec, rec, counts = metrics(y, yhat)\n",
    "print(\"Accuracy:\", round(acc, 3), \"Precision:\", round(prec, 3), \"Recall:\", round(rec, 3))\n",
    "print(\"TP,FP,FN,TN:\", counts)\n",
    "________________________________________\n",
    "Step 8 — See training improving (loss curve)\n",
    "Why plot\n",
    "Your eyes catch problems instantly (bad learning rate, stuck training).\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "________________________________________\n",
    "Mini “Babu” Experiments (these teach you fast)\n",
    "Experiment 1: Learning rate explosion\n",
    "Run training with lr=1.0 and watch loss go crazy.\n",
    "_ = train_logreg_gd(Xz, y, lr=1.0, steps=300, l2=0.01)\n",
    "Experiment 2: Underfitting vs overfitting feel\n",
    "•\ttry l2=0.0 and l2=0.2 and compare metrics\n",
    "Higher L2 usually reduces over-confidence.\n",
    "w1,b1,_ = train_logreg_gd(Xz, y, lr=0.15, steps=1200, l2=0.0)\n",
    "w2,b2,_ = train_logreg_gd(Xz, y, lr=0.15, steps=1200, l2=0.2)\n",
    "\n",
    "for name, ww, bb in [(\"l2=0.0\", w1, b1), (\"l2=0.2\", w2, b2)]:\n",
    "    yp = predict_label(Xz, ww, bb)\n",
    "    acc, prec, rec, _ = metrics(y, yp)\n",
    "    print(name, \"acc:\", round(acc,3), \"prec:\", round(prec,3), \"rec:\", round(rec,3))\n",
    "________________________________________\n",
    "The “notes you must write” (tiny and deadly useful)\n",
    "1.\tGradient Descent: params = params - lr * gradient\n",
    "2.\tSigmoid: 1 / (1 + exp(-z))\n",
    "3.\tCross-entropy: punishes confident wrong answers\n",
    "4.\tScaling helps gradient descent\n",
    "5.\tL2 regularization: adds l2*w to gradient\n",
    "________________________________________\n",
    "What Module 3 just gave you (real AI engineer muscle)\n",
    "•\tYou trained a model from scratch\n",
    "•\tYou saw how loss + gradient + learning rate control learning\n",
    "•\tYou used classification loss (cross-entropy)\n",
    "•\tYou evaluated like a grown-up (precision/recall, not only accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e04d0b-cffc-4ebe-b0fd-ee323a6c92ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Module 4 — Probability + Statistics for AI (Real-world)\n",
    "Why we need this in AI\n",
    "Because real life is noisy:\n",
    "•\tusers behave randomly\n",
    "•\tsensors are imperfect\n",
    "•\tlabels are wrong sometimes\n",
    "•\tdata shifts over time\n",
    "Probability helps you answer:\n",
    "•\t“How confident is this prediction?”\n",
    "•\t“What’s the chance of delay given rain + high traffic?”\n",
    "•\t“How do we combine evidence?”\n",
    "•\t“Why do we use log probabilities?”\n",
    "Statistics helps you answer:\n",
    "•\t“Is this improvement real or luck?” (A/B testing)\n",
    "•\t“What’s the distribution / uncertainty?”\n",
    "•\t“How to evaluate models properly?”\n",
    "________________________________________\n",
    "Topics you MUST learn in Module 4 (maximum + practical)\n",
    "A) Probability basics\n",
    "•\tevents, probability, independent vs dependent\n",
    "•\tconditional probability: P(A|B)\n",
    "B) Bayes rule (core AI idea)\n",
    "•\tupdate belief using evidence\n",
    "P(A|B) = P(B|A)P(A) / P(B)\n",
    "C) Distributions you actually need\n",
    "•\tBernoulli (yes/no), Binomial (count), Normal (noise), Poisson (rare events)\n",
    "D) Expectation & variance (average + uncertainty)\n",
    "•\texpected value = long-run average\n",
    "E) Log probabilities (super important)\n",
    "Multiplying tiny probabilities underflows → use logs to add.\n",
    "F) Evaluation metrics\n",
    "•\taccuracy, precision, recall, F1\n",
    "•\tthreshold tuning (0.5 is not magic)\n",
    "G) A/B test intuition (basic)\n",
    "•\t“is this improvement statistically meaningful?”\n",
    "________________________________________\n",
    "Real-world project (best practical)\n",
    "Project: Spam Detector (Naive Bayes) + Confidence + Threshold\n",
    "This is classic and still used:\n",
    "•\tspam filtering\n",
    "•\tticket routing\n",
    "•\tdocument classification\n",
    "•\tkeyword-based triage\n",
    "We will:\n",
    "1.\ttrain a Naive Bayes spam classifier from scratch\n",
    "2.\tuse log-probabilities (real-world method)\n",
    "3.\tproduce probability-like scores\n",
    "4.\ttune threshold to control false positives\n",
    "________________________________________\n",
    "Step 1 — Training dataset (toy but real logic)\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "spam_texts = [\n",
    "    \"win money now\",\n",
    "    \"cheap meds available\",\n",
    "    \"claim your prize now\",\n",
    "    \"limited offer win big\",\n",
    "    \"free gift claim now\"\n",
    "]\n",
    "\n",
    "ham_texts = [\n",
    "    \"meeting at noon\",\n",
    "    \"project update attached\",\n",
    "    \"can we reschedule the call\",\n",
    "    \"lunch tomorrow?\",\n",
    "    \"please review the document\"\n",
    "]\n",
    "\n",
    "def tokenize(text):\n",
    "    # WHY: simple tokenizer for learning (real projects use better tokenizers)\n",
    "    return re.findall(r\"[a-z']+\", text.lower())\n",
    "\n",
    "spam_tokens = [w for t in spam_texts for w in tokenize(t)]\n",
    "ham_tokens  = [w for t in ham_texts  for w in tokenize(t)]\n",
    "\n",
    "spam_counts = Counter(spam_tokens)\n",
    "ham_counts  = Counter(ham_tokens)\n",
    "\n",
    "vocab = sorted(set(spam_counts) | set(ham_counts))\n",
    "V = len(vocab)\n",
    "\n",
    "spam_total = sum(spam_counts.values())\n",
    "ham_total  = sum(ham_counts.values())\n",
    "\n",
    "print(\"Vocab size:\", V)\n",
    "print(\"Spam words:\", spam_counts.most_common(5))\n",
    "print(\"Ham  words:\", ham_counts.most_common(5))\n",
    "________________________________________\n",
    "Step 2 — Priors (base rates)\n",
    "Why\n",
    "If 90% emails are ham, model should start biased toward ham unless evidence says otherwise.\n",
    "P_spam = len(spam_texts) / (len(spam_texts) + len(ham_texts))\n",
    "P_ham  = 1 - P_spam\n",
    "\n",
    "logP_spam = np.log(P_spam)\n",
    "logP_ham  = np.log(P_ham)\n",
    "\n",
    "print(\"P_spam:\", P_spam, \"P_ham:\", P_ham)\n",
    "________________________________________\n",
    "Step 3 — Likelihoods with Laplace smoothing\n",
    "Why smoothing\n",
    "If a word never appeared in spam, probability becomes 0 and kills the whole product.\n",
    "Smoothing prevents “zero-probability death”.\n",
    "Laplace smoothing:\n",
    "P(word|class) = (count + alpha) / (total_words + alpha*V)\n",
    "alpha = 1.0\n",
    "\n",
    "def log_prob_word_given_class(word, counts, total, V, alpha=1.0):\n",
    "    return np.log((counts.get(word, 0) + alpha) / (total + alpha * V))\n",
    "________________________________________\n",
    "Step 4 — Score an email using log-probabilities\n",
    "Why logs\n",
    "Multiplying many tiny probabilities → underflow.\n",
    "So we do: log(a*b*c) = log(a)+log(b)+log(c).\n",
    "def score_email(text):\n",
    "    words = tokenize(text)\n",
    "\n",
    "    s_spam = logP_spam\n",
    "    s_ham  = logP_ham\n",
    "\n",
    "    for w in words:\n",
    "        s_spam += log_prob_word_given_class(w, spam_counts, spam_total, V, alpha)\n",
    "        s_ham  += log_prob_word_given_class(w, ham_counts,  ham_total,  V, alpha)\n",
    "\n",
    "    return s_spam, s_ham\n",
    "\n",
    "def predict(text, threshold=0.0):\n",
    "    # threshold is on log-odds difference: spam if (s_spam - s_ham) > threshold\n",
    "    s_spam, s_ham = score_email(text)\n",
    "    diff = s_spam - s_ham\n",
    "    label = \"SPAM\" if diff > threshold else \"HAM\"\n",
    "    return label, diff, s_spam, s_ham\n",
    "________________________________________\n",
    "Step 5 — Test it\n",
    "tests = [\n",
    "    \"win a free prize now\",\n",
    "    \"please review the project document\",\n",
    "    \"limited offer meds free\",\n",
    "    \"can we have lunch tomorrow\",\n",
    "]\n",
    "\n",
    "for t in tests:\n",
    "    label, diff, s_spam, s_ham = predict(t, threshold=0.0)\n",
    "    print(f\"{t!r:35} -> {label:4}  log_diff={diff:.3f}\")\n",
    "________________________________________\n",
    "Add “confidence” (soft probability)\n",
    "Naive Bayes gives log-scores. We can convert difference to a “probability-ish” value:\n",
    "If diff = log(Pspam) - log(Pham) then:\n",
    "P(spam) ≈ sigmoid(diff)\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "for t in tests:\n",
    "    label, diff, *_ = predict(t)\n",
    "    pspam = sigmoid(diff)\n",
    "    print(f\"{t!r:35} -> {label:4}  P(spam)≈{pspam:.2f}\")\n",
    "________________________________________\n",
    "Threshold tuning (real-world control)\n",
    "Why threshold matters\n",
    "•\tIn business, false positives (marking important mail as spam) are costly.\n",
    "•\tSo you raise threshold to be more conservative.\n",
    "thresholds = [-2, -1, 0, 1, 2]\n",
    "\n",
    "text = \"free prize now\"\n",
    "for thr in thresholds:\n",
    "    label, diff, *_ = predict(text, threshold=thr)\n",
    "    print(\"threshold:\", thr, \"->\", label, \"diff:\", round(diff,3))\n",
    "________________________________________\n",
    "Statistics mini: “Is improvement real?” (tiny A/B test intuition)\n",
    "If version A accuracy = 0.80 and version B = 0.82, is that real or luck?\n",
    "Quick practical check: simulate uncertainty using bootstrap.\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Suppose you tested on 200 emails:\n",
    "A_correct = np.random.binomial(1, 0.80, 200)\n",
    "B_correct = np.random.binomial(1, 0.82, 200)\n",
    "\n",
    "def bootstrap_mean(arr, B=2000):\n",
    "    n = len(arr)\n",
    "    means = []\n",
    "    for _ in range(B):\n",
    "        sample = np.random.choice(arr, size=n, replace=True)\n",
    "        means.append(sample.mean())\n",
    "    return np.array(means)\n",
    "\n",
    "A_boot = bootstrap_mean(A_correct)\n",
    "B_boot = bootstrap_mean(B_correct)\n",
    "\n",
    "diff = B_boot - A_boot\n",
    "print(\"Estimated mean improvement:\", diff.mean())\n",
    "print(\"95% interval:\", np.quantile(diff, 0.025), \"to\", np.quantile(diff, 0.975))\n",
    "If the 95% interval includes 0 → improvement might be luck.\n",
    "________________________________________\n",
    "Notes you MUST write (only the useful ones)\n",
    "1.\tConditional probability: P(A|B)\n",
    "2.\tBayes rule: P(A|B)=P(B|A)P(A)/P(B)\n",
    "3.\tLaplace smoothing prevents zero probability\n",
    "4.\tUse logs to avoid underflow\n",
    "5.\tThreshold controls false positives/negatives\n",
    "6.\tAccuracy can lie; use precision/recall\n",
    "________________________________________\n",
    "What Module 4 gives you (AI engineer reality)\n",
    "•\tYou can build a probabilistic classifier (Naive Bayes)\n",
    "•\tYou understand why logs are everywhere\n",
    "•\tYou can tune thresholds based on business risk\n",
    "•\tYou can judge if an improvement is real (basic stats thinking)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
